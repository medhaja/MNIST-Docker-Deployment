{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_test_inf, y_test_inf = x_test.copy(), y_test.copy()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2class = {0: \"Zero\",\n",
    "            1: \"One\",\n",
    "            2: \"Two\",\n",
    "            3: \"Three\",\n",
    "            4: \"Four\",\n",
    "            5: \"Five\",\n",
    "            6: \"Six\",\n",
    "            7: \"Seven\",\n",
    "            8: \"eight\",\n",
    "            9: \"Nine\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "844/844 [==============================] - 7s 4ms/step - loss: 0.2646 - accuracy: 0.9206 - val_loss: 0.0663 - val_accuracy: 0.9817\n",
      "Epoch 2/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0921 - accuracy: 0.9716 - val_loss: 0.0483 - val_accuracy: 0.9870\n",
      "Epoch 3/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0716 - accuracy: 0.9768 - val_loss: 0.0423 - val_accuracy: 0.9890\n",
      "Epoch 4/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0600 - accuracy: 0.9815 - val_loss: 0.0381 - val_accuracy: 0.9908\n",
      "Epoch 5/15\n",
      "844/844 [==============================] - 4s 5ms/step - loss: 0.0532 - accuracy: 0.9824 - val_loss: 0.0373 - val_accuracy: 0.9885\n",
      "Epoch 6/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.0344 - val_accuracy: 0.9902\n",
      "Epoch 7/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0432 - accuracy: 0.9864 - val_loss: 0.0351 - val_accuracy: 0.9900\n",
      "Epoch 8/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.0321 - val_accuracy: 0.9917\n",
      "Epoch 9/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.0318 - val_accuracy: 0.9923\n",
      "Epoch 10/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.0339 - val_accuracy: 0.9912\n",
      "Epoch 11/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0331 - accuracy: 0.9888 - val_loss: 0.0302 - val_accuracy: 0.9917\n",
      "Epoch 12/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0311 - accuracy: 0.9897 - val_loss: 0.0286 - val_accuracy: 0.9925\n",
      "Epoch 13/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 0.0318 - val_accuracy: 0.9920\n",
      "Epoch 14/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0298 - accuracy: 0.9898 - val_loss: 0.0285 - val_accuracy: 0.9923\n",
      "Epoch 15/15\n",
      "844/844 [==============================] - 3s 4ms/step - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0370 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de2fa2c400>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.02806621789932251\n",
      "Test accuracy: 0.9923999905586243\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "# model.save(\"d_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"Models/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Models/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Two')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1\n",
    "im = x_test_inf[idx]\n",
    "plt.imshow(im, cmap=\"gray\")\n",
    "plt.title(id2class[y_test_inf[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "# start_time = time.time()\n",
    "\n",
    "print(type(x_test_inf[idx]))\n",
    "im = x_test_inf[idx].tolist()\n",
    "data = {'image': im}\n",
    "URL = 'http://127.0.0.1:5000/predict'\n",
    "start_time = time.time()\n",
    "\n",
    "result = requests.post(URL, json.dumps(data))\n",
    "print(f\"Prediction = {result.text}\")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken = {end_time - start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('one.png')\n",
    "iamge = image.resize((28, 28))\n",
    "# image = image.tolist()\n",
    "\n",
    "newsize = (28, 28)\n",
    "image = image.resize(newsize)\n",
    "image = np.asarray(image)\n",
    "image = image.tolist()\n",
    "\n",
    "data = {'image': image}\n",
    "URL = 'http://127.0.0.1:5000/predict'\n",
    "\n",
    "result = requests.post(URL, json.dumps(data))\n",
    "print(f\"Prediction = {result.text}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54bd428ae3c8c7da62786e7f4f99fce11270d7e2d105794f22af38386a63a9cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
